# -*- coding: utf-8 -*-
"""B21ME048_B21ME060_B21CI018.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qbihiWS7OMykUv0Mo7UhB2ZlvXHQXY70

# Importing the Libraries
"""

import os
import argparse
from pydub import AudioSegment
import librosa
import soundfile as sf
from IPython.display import Audio, IFrame, display
import IPython.display as ipd
import matplotlib.pyplot as plt
from cmath import exp, pi
import numpy as np
import soundfile as sf

from scipy.io import wavfile
from scipy import signal

pip install pydub

import seaborn as sns

import librosa
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

def solution(i):
    # Load audio file using librosa
    samples, sampling_rate = librosa.load(i, duration=None, mono=True, sr=None, offset=0.0)
    
    # Convert samples to a NumPy array
    samples = np.array(samples)
    
    # Calculate duration of audio file
    duration = samples.shape[0] / sampling_rate
    
    # Plot audio waveform using Seaborn
    plt.figure(figsize=(10, 25))
    plt.subplot(3, 1, 1)
    plt.title(f'{sampling_rate} Hz')
    sns.lineplot(samples)
    plt.xlabel("freq (Hz)")
    plt.ylabel("magnitude")
    plt.show()

import librosa
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

def dft(x):
    """Calculate the Discrete Fourier Transform (DFT) of a signal using the formula."""
    N = len(x)
    X = np.zeros(N, dtype=np.complex)

    for k in range(N):
        for n in range(N):
            X[k] += x[n] * np.exp(-1j * 2 * np.pi * k * n / N)

    return X



def inbuilt_checking(i):
    # Load audio file using librosa
    samples, sampling_rate = librosa.load(i, duration=None, mono=True, sr=None, offset=0.0)
    
    # Convert samples to a NumPy array
    samples = np.array(samples)
    
    # Calculate absolute value of Fourier Transform
    Z=dft(samples)
    
    # Plot frequency spectrum using Seaborn
    plt.figure(figsize=(10, 25))
    plt.subplot(3, 1, 3)
    sns.lineplot(z)
    plt.xlabel("freq (Hz)")
    plt.ylabel("magnitude")
    plt.show()

files=['/content/B21CI018_S1_500.wav','/content/B21CI018_S1-2000.wav','/content/B21CI018_S1_16000.wav','/content/B21CI018_S2_500.wav','/content/B21CI018_S2_2000.wav','/content/B21CI018_S2_16000.wav','/content/B21CI018_S3_500.wav','/content/B21CI018_S3_2000.wav','/content/B21CI018_S3-16000.wav','/content/B21CI018_S4_500.wav','/content/B21CI018_S4_2000.wav','/content/B21CI018_S4_16000.wav','/content/B21ME048_s1_500.wav','/content/B21ME048_s1_2000.wav','/content/B21ME048_s1_16000.wav','/content/B21ME048_s2_500.wav','/content/B21ME048_s2_2000.wav','/content/B21ME048_s2_16000.wav','/content/B21ME048_s3_500.wav','/content/B21ME048_s3_2000.wav','/content/B21ME048_s3_16000.wav','/content/B21ME048_s4_500.wav','/content/B21ME048_s4_2000.wav','/content/B21ME048_s4_16000.wav','/content/B21ME060_S1_500.wav','/content/B21ME060_S1_2000.wav','/content/B21ME060_S1_16000.wav','/content/B21ME060_S2_500.wav','/content/B21ME060_S2_2000.wav','/content/B21ME060_S2_16000.wav','/content/B21ME060_S3_500.wav','/content/B21ME060_S3_2000.wav','/content/B21ME060_S3_16000.wav','/content/B21ME060_S4_500.wav','/content/B21ME060_S4_2000.wav','/content/B21ME060_S4_16000.wav']
for i in files:
  solution(i)

for i in files:
  inbuilt_checking(i)

# Loop through the file paths and analyze each recording
for i in range(len(files)):
    # Load audio file using librosa
    samples, sampling_rate = librosa.load(files[i], duration=None, mono=True, sr=None, offset=0.0)
    # Convert samples to a NumPy array
    samples = np.array(samples)
    # Compute the one-dimensional discrete Fourier Transform
    yf=dft(samples)
    # Compute the power spectral density of the signal
    psd=np.abs(yf)**2/len(samples)
    # Plot the power spectral density
    plt.figure()
    sns.lineplot(psd)
    plt.xlabel("frequency (Hz)")
    plt.ylabel("Amplitude")
    plt.title(f"Recording {i+1}: {files[i]}")
    plt.show()

!pip install PyWavelets

def dnoise(filename):
  audio, sr = sf.read(filename)
  a,b=(2,4)
  # Define the wavelet and thresholding function
  wavelet = pywt.Wavelet('db4')  # Choose a wavelet
  level = a  # Choose the number of decomposition levels
  threshold = np.std(audio) / b  # Choose the threshold value
  mode = 'soft'  # Choose the thresholding mode

  # Perform the wavelet decomposition and thresholding
  coeffs = pywt.wavedec(audio, wavelet, level=level)
  coefficient_thresholds=[]
  for c in coeffs:
    coefficient_thresholds.append(pywt.threshold(c, threshold, mode))

  # Reconstruct the denoised audio signal
  audio_denoised = pywt.waverec(coeffs_thresh, wavelet)

  # Plot the noisy and denoised audio signals
  plt.figure(figsize=(15,7))
  plt.subplot(2,1,1)
  plt.plot(audio,color="red")
  plt.title('Original Audio')
  plt.xlabel('Index')
  plt.ylabel('Amplitude(A)')
  plt.subplot(2,1,2)
  plt.plot(audio_denoised)
  plt.title('Denoised Audio')
  plt.xlabel('Index')
  plt.ylabel('Amplitude(A)')
  plt.tight_layout()
  plt.show()

  # Write the denoised audio to a new file
  sf.write('denoised_audio.wav', audio_denoised, sr)

for filename in files:
  dnoise(filename)

